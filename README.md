# Practice5

Контрольные вопросы
1. В чём отличие стека и очереди?
Стек (Stack) и очередь (Queue) — это две фундаментальные структуры данных, отличающиеся принципом доступа к элементам. Стек: Работает по принципу LIFO (Last In, First Out) — последний добавленный элемент извлекается первым. Операции: push (добавление) и pop (извлечение) с вершины. Применяется для рекурсии, undo-операций, парсинга выражений.
Очередь: Работает по принципу FIFO (First In, First Out) — первый добавленный элемент извлекается первым. Операции: enqueue (добавление в конец) и dequeue (извлечение с начала). Применяется для задач планирования, буферизации, BFS (поиск в ширину). Основное отличие в порядке обработки элементов: стек — "стопка тарелок" (снимаешь сверху), очередь — "очередь в магазине" (первый пришел, первый ушел).
2. Какие проблемы возникают при параллельном доступе к данным?
Состояние гонки (Race Condition): Когда результат зависит от порядка выполнения потоков, приводя к непредсказуемым результатам (например, два потока инкрементируют переменную одновременно, и итог неверный). Мертвая блокировка (Deadlock): Потоки ждут друг друга, блокируя ресурсы, и система замирает.
3. Как атомарные операции помогают избежать конфликтов в
параллельных структурах данных?
Атомарные операции — это инструкции, выполняемые как единое, неделимое действие, без прерывания другими потоками. Они предотвращают состояния гонки, обеспечивая, что операция (например, инкремент или обмен) завершается полностью перед тем, как другой поток сможет вмешаться.
4. Какие типы памяти CUDA используются для хранения данных?
Глобальная память (Global Memory): Доступна всем потокам, большая (гигабайты), но медленная (высокая latency). Используется для больших данных.
Разделяемая память (Shared Memory): Доступна потокам в одном блоке, быстрая (как кэш), малая (килобайты на блок). Для обмена данными внутри блока.
Константная память (Constant Memory): Только для чтения, кэшируется, быстрая для констант.
Текстурная память (Texture Memory): Оптимизирована для 2D/3D данных, с кэшированием и фильтрацией.
Регистры (Registers): Самая быстрая, локальная для каждого потока, ограниченная (тысячи на поток).
Локальная память (Local Memory): Для переполнения регистров, но медленная, как глобальная.
5. Как синхронизация потоков влияет на производительность?
Положительное влияние: Предотвращает ошибки (например, race conditions), позволяя эффективно использовать многоядерные системы.
Отрицательное влияние: Вводит overhead — потоки тратят время на ожидание (спинлоки, мьютексы), что приводит к простою, снижению параллелизма и потенциальному амдалевскому закону (последовательные части ограничивают speedup). В GPU (CUDA) барьеры вроде __syncthreads() останавливают warp'ы, вызывая дивергенцию и потерю throughput.
6. Почему разделяемая память важна для оптимизации работы
параллельных структур данных?
Снижение latency: Доступ к shared memory в 100+ раз быстрее глобальной, уменьшая задержки на чтение/запись.
Сокращение трафика: Потоки загружают данные из глобальной памяти в shared один раз, затем используют локально, минимизируя обращения к медленной памяти.
Кооперация потоков: Позволяет потокам в блоке обмениваться данными без глобальной синхронизации, оптимизируя структуры вроде параллельных очередей или стеков (например, в редукции или матричных операциях).
